{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21pElqOwyZXD"
   },
   "source": [
    "# COMP5046 - Natural Language Processing Assignment 2: QandA Bot\n",
    "Brandon James Temple  \n",
    "BTEM3257  \n",
    "460372949  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nLR3ZdrDyvUU"
   },
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IhhV99MM620u",
    "outputId": "6ef1bca8-d2fa-45eb-cae7-890b3da31bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10kB 19.4MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 30kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 40kB 3.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 51kB 3.8MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 61kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 71kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 81kB 5.9MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 92kB 6.6MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 102kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 112kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 122kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 133kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 143kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 153kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 163kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 174kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 184kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 194kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 204kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 215kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 225kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 235kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 245kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 256kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 266kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 276kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 286kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 296kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 307kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 317kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 327kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 337kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 348kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 358kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 368kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 378kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 389kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 399kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 409kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 419kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 430kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 440kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 450kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 460kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 471kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 481kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 491kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 501kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 512kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 522kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 532kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 542kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 552kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 563kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 573kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 583kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 593kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 604kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 614kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 624kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 634kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 645kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 655kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 665kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 675kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 686kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 696kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 706kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 716kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 727kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 737kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 747kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 757kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 768kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 778kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 788kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 798kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 808kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 819kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 829kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 839kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 849kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 860kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 870kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 880kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 890kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 901kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 911kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 921kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 931kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 942kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 952kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 962kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 972kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 983kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 993kB 5.1MB/s \n",
      "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Code to download file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Download all three Microsoft BotBuilder Personality Chat Datasets on Google Colab virtual server\n",
    "\n",
    "id = '1SXoGbD9WZHwhpqR-cBw7-8_7Ri06nIb6'\n",
    "downloaded = drive.CreateFile({'id':id }) \n",
    "downloaded.GetContentFile('WikiQA-train.tsv') \n",
    "\n",
    "id = '1TwuDSxlcAFDnTRpF-GRvqRXoR_UsJznH'\n",
    "downloaded = drive.CreateFile({'id':id }) \n",
    "downloaded.GetContentFile('WikiQA-test.tsv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XlFZL0uTbay"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# train.tsv\n",
    "df_train=pd.read_csv('WikiQA-train.tsv', sep='\\t')\n",
    "# test.tsv\n",
    "df_test=pd.read_csv('WikiQA-test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEdwbRNmTiCT"
   },
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "test_dataset = []\n",
    "max_document_len = 0\n",
    "max_question_len = 0\n",
    "max_document_sents = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HpokYWHTkPF"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "q_id = -1\n",
    "a_i_count = 0\n",
    "no_answer = True\n",
    "curr_triplet = {}\n",
    "for row in df_train.iterrows():\n",
    "    curr_q_id = row[1]['QuestionID']\n",
    "    if q_id == -1:\n",
    "        q_id = curr_q_id\n",
    "    if curr_q_id != q_id:\n",
    "        if no_answer:\n",
    "            curr_triplet['answer'] = -1\n",
    "        if len(curr_triplet['question']) > max_question_len:\n",
    "            max_question_len = len(curr_triplet['question'])\n",
    "        if #sum doc lengths > max_document_len:\n",
    "            max_document_len = # sum of doc sent lengths\n",
    "        if len(curr_triplet['document']) > max_document_sents:\n",
    "            max_document_sents = len(curr_triplet['document'])\n",
    "        train_dataset.append(curr_triplet)\n",
    "        curr_triplet = {}\n",
    "        a_i_count = 0\n",
    "        no_answer = True\n",
    "        q_id = curr_q_id\n",
    "    question =  row[1]['Question']\n",
    "    document =  row[1]['Sentence']\n",
    "    is_answer =  row[1]['Label']\n",
    "    if not ('question' in curr_triplet):\n",
    "        curr_triplet['question'] = question.replace('-', ' ').replace('—', ', ')\n",
    "    if not ('document' in curr_triplet):\n",
    "        curr_triplet['document'] = [document.replace('-', ' ').replace('—', ', ')]\n",
    "    else:\n",
    "        curr_triplet['document'].append(document.replace('-', ' ').replace('—', ', '))\n",
    "    if is_answer == 1:\n",
    "        curr_triplet['answer'] = a_i_count\n",
    "        no_answer = False\n",
    "    else:\n",
    "        a_i_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xnf9mgTJTlGd"
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "q_id = -1\n",
    "a_i_count = 0\n",
    "no_answer = True\n",
    "curr_triplet = {}\n",
    "for row in df_train.iterrows():\n",
    "    curr_q_id = row[1]['QuestionID']\n",
    "    if q_id == -1:\n",
    "        q_id = curr_q_id\n",
    "    if curr_q_id != q_id:\n",
    "        if no_answer:\n",
    "            curr_triplet['answer'] = -1\n",
    "        test_dataset.append(curr_triplet)\n",
    "        curr_triplet = {}\n",
    "        a_i_count = 0\n",
    "        no_answer = True\n",
    "        q_id = curr_q_id\n",
    "    question =  row[1]['Question']\n",
    "    document =  row[1]['Sentence']\n",
    "    is_answer =  row[1]['Label']\n",
    "    if not ('question' in curr_triplet):\n",
    "        curr_triplet['question'] = question.replace('-', ' ').replace('—', ', ')\n",
    "    if not ('document' in curr_triplet):\n",
    "        curr_triplet['document'] = [document.replace('-', ' ').replace('—', ', ')]\n",
    "    else:\n",
    "        curr_triplet['document'].append(document.replace('-', ' ').replace('—', ', '))\n",
    "    if is_answer == 1:\n",
    "        curr_triplet['answer'] = a_i_count\n",
    "        no_answer = False\n",
    "    else:\n",
    "        a_i_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNX7xrjI8zaa"
   },
   "outputs": [],
   "source": [
    "# combine datasets\n",
    "full_dataset = train_dataset + test_dataset\n",
    "\n",
    "# clear unneeded data from memory\n",
    "del df_train\n",
    "del df_test\n",
    "del train_dataset\n",
    "del test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rPlFI2kvy0XI"
   },
   "source": [
    "# 2. Q&A Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ggjbWss_zEjb"
   },
   "source": [
    "## 2.1 Word Embedding and Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4ZGyWVzzahX"
   },
   "source": [
    "### 2.1.1 Word Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CtSYXBZE4Tiu"
   },
   "source": [
    "**WARNING**: This could max out the ram but it shouldn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "OkBYemwlj2W4",
    "outputId": "9f03cdef-8414-4be7-d7cc-8860c28ec073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-10 09:26:24--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4503593528 (4.2G) [application/octet-stream]\n",
      "Saving to: ‘cc.en.300.bin.gz’\n",
      "\n",
      "cc.en.300.bin.gz    100%[===================>]   4.19G  33.6MB/s    in 1m 50s  \n",
      "\n",
      "2019-06-10 09:28:15 (38.9 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
    "! gunzip cc.en.300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnWOVp5rm11g"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "word_embedding = FastText.load_fasttext_format('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tucrlDszzepW"
   },
   "source": [
    "### 2.1.2 Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "514w4MqDzxKJ"
   },
   "source": [
    "#### 2.1.2.1 POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "0RnakKpmQBI4",
    "outputId": "7dd687ce-f145-4627-e57b-87e121a7b2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK Imports and downloads\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "\n",
    "from nltk.tag import hmm\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Train a tagger\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "trained_tagger = trainer.train_supervised(brown.tagged_sents())\n",
    "\n",
    "# Define function to tag sentences\n",
    "# NEED TO BREAK IN SENTENCE AND WHOLE STRING\n",
    "def pos_tag(tokens):\n",
    "    tags = []\n",
    "    for tagged_word in trained_tagger.tag(tokens):\n",
    "        tag = tagged_word[1]\n",
    "        if tag.startswith('NN'):\n",
    "            tags.append([1,0,0,0])\n",
    "        elif tag.startswith('JJ'):\n",
    "            tags.append([0,1,0,0])\n",
    "        elif tag.startswith('RB'):\n",
    "            tags.append([0,0,1,0])\n",
    "        elif tag.startswith('VB'):\n",
    "            tags.append([0,0,0,1])\n",
    "        else:\n",
    "            tags.append([0,0,0,0])\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47AtpD6Dz2qn"
   },
   "source": [
    "#### 2.1.2.2 TF-IDF\n",
    "The Document in whole is treated as the Corpus and each sentence a Document for frequency purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7ZqV9Y1R6Kf"
   },
   "outputs": [],
   "source": [
    "# Collections and math import\n",
    "import collections\n",
    "import math\n",
    "\n",
    "# Define function to calculate word frequencies\n",
    "def tfidf(sentences):\n",
    "    whole_scores = []\n",
    "    N = len(sentences)\n",
    "    corpus = sum(sentences, [])\n",
    "    corpus_counter = collections.Counter(corpus)\n",
    "    sentence_counters = []\n",
    "    for s in sentences:\n",
    "        sentence_counters.append(collections.Counter(s))\n",
    "    for i in range(len(sentences)):\n",
    "        current_counter = sentence_counters[i]\n",
    "        for word in sentences[i]:\n",
    "            tf = current_counter[word]\n",
    "            df = 0\n",
    "            for counter in sentence_counters:\n",
    "                if counter[word] > 0:\n",
    "                    df += 1\n",
    "            weight = tf * math.log(N/df)\n",
    "            whole_scores.append(weight)\n",
    "    return whole_scores\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPIDaVESz8Z9"
   },
   "source": [
    "#### 2.1.2.3 Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "EoWZDSS9Xll4",
    "outputId": "6a3b6fab-4298-4e42-8828-39cbdb1e80b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/5b/0fab3fa533229436533fb504bb62f4cf7ea29541a487a9d1a0749876fc23/spacy-2.1.4-cp36-cp36m-manylinux1_x86_64.whl (29.8MB)\n",
      "\u001b[K     |████████████████████████████████| 29.8MB 1.5MB/s \n",
      "\u001b[?25hCollecting thinc<7.1.0,>=7.0.2 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/f1/3df317939a07b2fc81be1a92ac10bf836a1d87b4016346b25f8b63dee321/thinc-7.0.4-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 39.3MB/s \n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.2.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/c1/d76ccdd12c716be79162d934fe7de4ac8a318b9302864716dde940641a79/wasabi-0.2.2-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
      "Collecting srsly<1.1.0,>=0.0.5 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/ed/dadafaf4685d261e9a9583e4b27c5d94ae162b1435439d7eadf261d34c01/srsly-0.0.6-cp36-cp36m-manylinux1_x86_64.whl (180kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 44.2MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
      "Collecting blis<0.3.0,>=0.2.2 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 37.1MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy) (4.28.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Installing collected packages: blis, srsly, wasabi, thinc, spacy\n",
      "  Found existing installation: thinc 6.12.1\n",
      "    Uninstalling thinc-6.12.1:\n",
      "      Successfully uninstalled thinc-6.12.1\n",
      "  Found existing installation: spacy 2.0.18\n",
      "    Uninstalling spacy-2.0.18:\n",
      "      Successfully uninstalled spacy-2.0.18\n",
      "Successfully installed blis-0.2.4 spacy-2.1.4 srsly-0.0.6 thinc-7.0.4 wasabi-0.2.2\n",
      "Collecting en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1MB 779kB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qlhjs0tt/wheels/39/ea/3b/507f7df78be8631a7a3d7090962194cf55bc1158572c0be77f\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Found existing installation: en-core-web-sm 2.0.0\n",
      "    Uninstalling en-core-web-sm-2.0.0:\n",
      "      Successfully uninstalled en-core-web-sm-2.0.0\n",
      "Successfully installed en-core-web-sm-2.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rosrjF2azd-n"
   },
   "source": [
    "Tests for Person, Organistion, Date, NORP, and GPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozpsQlC7XZmx"
   },
   "outputs": [],
   "source": [
    "# THIS MIGHT TOKENISE THINGS DIFFERENTLY WHICH WILL CAUSE PROBLEMS\n",
    "# Import spacy and en_core\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "# Load NER model\n",
    "recogniser = en_core_web_sm.load()\n",
    "\n",
    "def ner(tokens):\n",
    "    sentence = recogniser(tokens)\n",
    "    entities = [(x, x.ent_iob_, x.ent_type_) for x in sentence]\n",
    "    tags = []\n",
    "    for entity in entities:\n",
    "        tag = []\n",
    "        # is it an entity?\n",
    "        if entity[1] == 'O':\n",
    "            tag += [0]\n",
    "        else:\n",
    "            tag += [1]\n",
    "        \n",
    "        # if entity, is it I or B?\n",
    "        if entity[1] == 'B':\n",
    "            tag += [1, 0]\n",
    "        elif entity[1] == 'I':\n",
    "            tag += [0, 1]\n",
    "        else:\n",
    "            tag += [0, 0]\n",
    "            \n",
    "        # if entity, what type?\n",
    "        if entity[2] == 'PERSON':\n",
    "            tag += [1,0,0,0,0,0]\n",
    "        elif entity[2] == 'DATE':\n",
    "            tag += [0,1,0,0,0,0]\n",
    "        elif entity[2] == 'ORG':\n",
    "            tag += [0,0,1,0,0,0]\n",
    "        elif entity[2] == 'NORP':\n",
    "            tag += [0,0,0,1,0,0]\n",
    "        elif entity[2] == 'GPE':\n",
    "            tag += [0,0,0,0,1,0]\n",
    "        elif entity[2] == '':\n",
    "            tag += [0,0,0,0,0,0]\n",
    "        else:\n",
    "            tag += [0,0,0,0,0,1]\n",
    "        tags.append(tag)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjqLJ1OF0BrJ"
   },
   "source": [
    "#### 2.1.2.4 Dependancy Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6SevxjWXa1Ms"
   },
   "outputs": [],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yXZow4vNYc34"
   },
   "outputs": [],
   "source": [
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "# Download parser\n",
    "pather = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def dependancy_path(sentences):\n",
    "    heads = []\n",
    "    for sentence in sentences:\n",
    "        parse = pather(sentence)\n",
    "        for token in parse:\n",
    "            if token.dep_ == 'ROOT':\n",
    "                heads.append([-1])\n",
    "            else:\n",
    "                heads.append([token.head.i])\n",
    "    return heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nEEQx_7v7pGB"
   },
   "source": [
    "#### 2.1.2.5 Word Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "doTOAVMO7tWL",
    "outputId": "cc82f02f-f8c5-4cee-883b-4db778eddca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import NLTK, and download Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "def word_match(sentence, question):\n",
    "    matches = []\n",
    "    # lemmatise question\n",
    "    question_lemmatised = [lemmatiser.lemmatize(x.lower()) for x in question]\n",
    "    # check is lemmatised word in question\n",
    "    for word in sentence:\n",
    "        if lemmatiser.lemmatize(word.lower()) in question_lemmatised:\n",
    "            matches.append(1)\n",
    "        else:\n",
    "            matches.append(0)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UhkOhQCw6-FU"
   },
   "source": [
    "### 2.1.3 Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnvpGzp57Evc"
   },
   "source": [
    "You can change these variables to alter which features are used when not using the automated evaluation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eMt9k2t68SG"
   },
   "outputs": [],
   "source": [
    "use_pos = False\n",
    "use_tfidf = False\n",
    "use_ner = False\n",
    "use_dpath = False\n",
    "use_matching = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4QoIizS3zIQH"
   },
   "source": [
    "## 2.2 Sequence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ir6RKK8URXL"
   },
   "source": [
    "### 2.2.1 Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSVeF8HuVGWU"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def generate_batch(dataset):\n",
    "    document_batch = []\n",
    "    question_batch = []\n",
    "    answer_batch = []\n",
    "    documents = []\n",
    "    questions = []\n",
    "    answer_keys = []\n",
    "    doc_vec_len = 0\n",
    "    for i in range(len(dataset)):\n",
    "        data = dataset[i]\n",
    "        question = data['question']\n",
    "        document_sentences = data['document']\n",
    "        document_whole = ''.join(document_sentences)\n",
    "        \n",
    "        # tokenise\n",
    "        question_tokens = question.split(' ')\n",
    "        document_whole_tokens = document_whole.split(' ')\n",
    "        document_sentence_tokens = []\n",
    "        for sentence in document_sentences:\n",
    "            document_sentence_tokens.append(sentence.split(' '))\n",
    "            \n",
    "        \n",
    "        # make token vectors\n",
    "        question_vectors = []\n",
    "        for token in question_tokens:\n",
    "            word = token.lower()\n",
    "            word = re.sub(r'[^\\w\\s]','', word)\n",
    "            if word == '':\n",
    "                continue\n",
    "            try:\n",
    "                question_vectors.append(list(word_embedding[word]))\n",
    "            except:\n",
    "                question_vectors.append([0]*300)\n",
    "        document_vectors = []\n",
    "        for token in document_whole_tokens:\n",
    "            word = token.lower()\n",
    "            word = re.sub(r'[^\\w\\s]','', word)\n",
    "            if word == '':\n",
    "                continue\n",
    "            try:\n",
    "                document_vectors.append(list(word_embedding[word]))\n",
    "            except:\n",
    "                question_vectors.append([0]*300)\n",
    "        print ('\\r %d of %d processing...' % (i+1, len(dataset)), end='')\n",
    "        \n",
    "        # extract features\n",
    "        if use_pos:\n",
    "            tags = pos_tag(document_whole)\n",
    "            for i in range(len(document_vectors)):\n",
    "                document_vectors[i] += tags[i]\n",
    "                \n",
    "        if use_tfidf:\n",
    "            freqs = tfidf(document_sentence_tokens)\n",
    "            for i in range(len(document_vectors)):\n",
    "                document_vectors[i] += [freqs[i]]\n",
    "                \n",
    "        if use_ner:\n",
    "            tags = ner(document_whole)\n",
    "            for i in range(len(document_vectors)):\n",
    "                document_vectors[i] += tags[i]\n",
    "                \n",
    "        if use_dpath:\n",
    "            heads = dependancy_path(document_sentences)\n",
    "            for i in range(len(document_vectors)):\n",
    "                document_vectors[i] += heads[i]\n",
    "                \n",
    "        if use_matching:\n",
    "            match = word_match(document_whole_tokens, question_tokens)\n",
    "            for i in range(len(document_vectors)):\n",
    "                document_vectors[i] += [match[i]]\n",
    "        \n",
    "        doc_vec_len = len(document_vectors[0])\n",
    "        for vector in document_vectors:\n",
    "            vector = np.array(vector)\n",
    "        for vector in question_vectors:\n",
    "            vector = np.array(vector)\n",
    "        \n",
    "        # add to batches\n",
    "        documents.append(document_vectors)\n",
    "        questions.append(question_vectors)\n",
    "        answer_keys.append(data['answer'])\n",
    "        \n",
    "    # Pad Doc and Q Batches:\n",
    "    for document in documents:\n",
    "        difference = max_document_len - len(document)\n",
    "        for _ in range(difference):\n",
    "            document.append(np.array([0]*doc_vec_len))\n",
    "        document_batch.append(np.array(document))\n",
    "        \n",
    "    for question in questions:\n",
    "        difference = max_question_len - len(question)\n",
    "        for _ in range(difference):\n",
    "            question.append(np.array([0]*300))\n",
    "        question_batch.append(np.array(question))\n",
    "        \n",
    "    # transform answer to 1hot\n",
    "    for answer in answer_keys:\n",
    "        i = np.eye(max_document_sents+1)\n",
    "        vector = i[answer]\n",
    "        answer_batch.append(vector)\n",
    "    return np.array(document_batch), np.array(question_batch), np.array(answer_batch)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XmzWUg7UUIY"
   },
   "source": [
    "### 2.2.2 Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tP4wZgyyWUzM",
    "outputId": "2a4d1acc-5898-48f1-ec72-7811943c2d35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dot\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Softmax\n",
    "from keras.layers import Flatten\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "# precision and recall code are as they originally were in Keras, see:\n",
    "# Title: Keras Source Code\n",
    "# Author: carlthome\n",
    "# Date: 4 Nov 2016\n",
    "# Commit: https://github.com/keras-team/keras/commit/2b51317be82d4420169d2cc79dc4443028417911#diff-7b49e1c42728a58a9d08643a79f44cd4\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2*((p*r)/(p+r))\n",
    "\n",
    "def create_model(feature_len, answer_len, doc_len, q_len):\n",
    "    # document\n",
    "    document_input = Input(shape=(doc_len,feature_len), name='document_embeddingsfeatures')\n",
    "    document_bilstm = Bidirectional(LSTM(answer_len, return_sequences=True), name ='document_bilstm', merge_mode='sum')(document_input)\n",
    "    \n",
    "    # question\n",
    "    question_input = Input(shape=(q_len,300), name='question_embeddings')\n",
    "    question_bilstm = Bidirectional(LSTM(answer_len, return_sequences=True), name='question_bilstm', merge_mode='sum')(question_input)\n",
    "    \n",
    "    # attention\n",
    "    attention = Dot(name='attention_dot_score', axes=(2,2))([document_bilstm, question_bilstm])\n",
    "    reshape = Flatten()(attention)\n",
    "    dense = Dense(answer_len)(reshape)\n",
    "    softmax = Softmax(axis=1, name='attenion_softmax')(dense)\n",
    "    \n",
    "    model = Model(inputs = [document_input, question_input], outputs = softmax)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['acc', precision, recall, fscore],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEGcWukOUWoi"
   },
   "source": [
    "### 2.2.3 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYIXMifYhnK_"
   },
   "outputs": [],
   "source": [
    "def train_model(model, document_batch, question_batch, answer_batch, epoch_num):\n",
    "    model.fit([document_batch, question_batch], answer_batch, batch_size=10, epochs=epoch_num, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QfKkr7LzNVJ"
   },
   "source": [
    "## 2.3 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alzcbysik-d0"
   },
   "source": [
    "### 2.3.1 Which Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 29083
    },
    "colab_type": "code",
    "id": "9tdhGleyhBw4",
    "outputId": "257cbf1b-c33d-4c37-cdf7-38b0c1cee44f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: True\ttfidf: False\tner: False\tdpath: False\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 0.0245 - acc: 0.5900 - precision: 0.4175 - recall: 0.3500 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0228 - acc: 0.5950 - precision: 0.5950 - recall: 0.5950 - fscore: 0.5950\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0187 - acc: 0.6400 - precision: 0.6756 - recall: 0.5350 - fscore: 0.5913\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0178 - acc: 0.6400 - precision: 0.6759 - recall: 0.5850 - fscore: 0.6234\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0164 - acc: 0.6500 - precision: 0.7425 - recall: 0.6100 - fscore: 0.6661\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0150 - acc: 0.6800 - precision: 0.7685 - recall: 0.6250 - fscore: 0.6846\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0128 - acc: 0.7150 - precision: 0.8680 - recall: 0.6450 - fscore: 0.7345\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0100 - acc: 0.7850 - precision: 0.9078 - recall: 0.7100 - fscore: 0.7918\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0097 - acc: 0.8000 - precision: 0.8674 - recall: 0.7750 - fscore: 0.8161\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0075 - acc: 0.8500 - precision: 0.9112 - recall: 0.8100 - fscore: 0.8535\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0064 - acc: 0.8850 - precision: 0.9103 - recall: 0.8600 - fscore: 0.8836\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0053 - acc: 0.9100 - precision: 0.9322 - recall: 0.9000 - fscore: 0.9150\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0055 - acc: 0.9050 - precision: 0.9171 - recall: 0.9000 - fscore: 0.9078\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0042 - acc: 0.9200 - precision: 0.9294 - recall: 0.9200 - fscore: 0.9245\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0039 - acc: 0.9300 - precision: 0.9400 - recall: 0.9300 - fscore: 0.9347\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0039 - acc: 0.9350 - precision: 0.9400 - recall: 0.9350 - fscore: 0.9374\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9350 - precision: 0.9394 - recall: 0.9350 - fscore: 0.9371\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0039 - acc: 0.9350 - precision: 0.9350 - recall: 0.9350 - fscore: 0.9350\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0048 - acc: 0.9200 - precision: 0.9200 - recall: 0.9200 - fscore: 0.9200\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0057 - acc: 0.9100 - precision: 0.9150 - recall: 0.9050 - fscore: 0.9094\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0047 - acc: 0.9250 - precision: 0.9250 - recall: 0.9200 - fscore: 0.9224\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9444 - recall: 0.9400 - fscore: 0.9421\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9444 - recall: 0.9400 - fscore: 0.9421\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9444 - recall: 0.9400 - fscore: 0.9421\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9444 - recall: 0.9400 - fscore: 0.9421\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9444 - recall: 0.9400 - fscore: 0.9421\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9444 - recall: 0.9400 - fscore: 0.9421\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9444 - recall: 0.9400 - fscore: 0.9421\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9444 - recall: 0.9400 - fscore: 0.9421\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "testing\n",
      "100/100 [==============================] - 4s 43ms/step\n",
      "[0.024920746218413115, 0.5300000041723252, 0.5661111146211624, 0.5200000077486038, 0.5408187299966812]\n",
      "pos: False\ttfidf: True\tner: False\tdpath: False\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 0.0257 - acc: 0.5650 - precision: 0.4412 - recall: 0.3700 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0240 - acc: 0.6200 - precision: 0.6200 - recall: 0.6200 - fscore: 0.6200\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0231 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0230 - acc: 0.6400 - precision: 0.6433 - recall: 0.6400 - fscore: 0.6416\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6376 - recall: 0.6250 - fscore: 0.6307\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0227 - acc: 0.6450 - precision: 0.6494 - recall: 0.6400 - fscore: 0.6445\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0228 - acc: 0.6450 - precision: 0.6450 - recall: 0.6400 - fscore: 0.6424\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0227 - acc: 0.6400 - precision: 0.6469 - recall: 0.6300 - fscore: 0.6378\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0228 - acc: 0.6000 - precision: 0.6542 - recall: 0.5700 - fscore: 0.6060\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0222 - acc: 0.6400 - precision: 0.6589 - recall: 0.6350 - fscore: 0.6463\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0224 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0227 - acc: 0.6450 - precision: 0.6450 - recall: 0.6450 - fscore: 0.6450\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0223 - acc: 0.6450 - precision: 0.6489 - recall: 0.6450 - fscore: 0.6468\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0233 - acc: 0.6050 - precision: 0.6117 - recall: 0.6050 - fscore: 0.6082\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0223 - acc: 0.6450 - precision: 0.6483 - recall: 0.6450 - fscore: 0.6466\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0248 - acc: 0.6000 - precision: 0.6079 - recall: 0.5950 - fscore: 0.6009\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0259 - acc: 0.5700 - precision: 0.5750 - recall: 0.5700 - fscore: 0.5722\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0229 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0234 - acc: 0.6300 - precision: 0.6333 - recall: 0.6300 - fscore: 0.6316\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0237 - acc: 0.6200 - precision: 0.6272 - recall: 0.6200 - fscore: 0.6234\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0227 - acc: 0.6400 - precision: 0.6394 - recall: 0.6350 - fscore: 0.6371\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0225 - acc: 0.6400 - precision: 0.6472 - recall: 0.6400 - fscore: 0.6434\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0221 - acc: 0.6500 - precision: 0.6583 - recall: 0.6500 - fscore: 0.6539\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0218 - acc: 0.6550 - precision: 0.6583 - recall: 0.6500 - fscore: 0.6539\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0210 - acc: 0.6650 - precision: 0.6694 - recall: 0.6650 - fscore: 0.6671\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0212 - acc: 0.6650 - precision: 0.6650 - recall: 0.6650 - fscore: 0.6650\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0226 - acc: 0.6400 - precision: 0.6433 - recall: 0.6400 - fscore: 0.6416\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0219 - acc: 0.6500 - precision: 0.6539 - recall: 0.6500 - fscore: 0.6518\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0211 - acc: 0.6650 - precision: 0.6739 - recall: 0.6650 - fscore: 0.6692\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0207 - acc: 0.6750 - precision: 0.6767 - recall: 0.6700 - fscore: 0.6732\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0205 - acc: 0.6800 - precision: 0.6800 - recall: 0.6800 - fscore: 0.6800\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0204 - acc: 0.6800 - precision: 0.6867 - recall: 0.6800 - fscore: 0.6832\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0202 - acc: 0.6850 - precision: 0.6850 - recall: 0.6850 - fscore: 0.6850\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0264 - acc: 0.5900 - precision: 0.5861 - recall: 0.5850 - fscore: 0.5855\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0258 - acc: 0.5950 - precision: 0.5950 - recall: 0.5950 - fscore: 0.5950\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0207 - acc: 0.6750 - precision: 0.6750 - recall: 0.6750 - fscore: 0.6750\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0203 - acc: 0.6850 - precision: 0.6850 - recall: 0.6850 - fscore: 0.6850\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0202 - acc: 0.6850 - precision: 0.6850 - recall: 0.6850 - fscore: 0.6850\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0202 - acc: 0.6850 - precision: 0.6850 - recall: 0.6850 - fscore: 0.6850\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0202 - acc: 0.6850 - precision: 0.6850 - recall: 0.6850 - fscore: 0.6850\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0202 - acc: 0.6850 - precision: 0.6850 - recall: 0.6850 - fscore: 0.6850\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0202 - acc: 0.6850 - precision: 0.6850 - recall: 0.6850 - fscore: 0.6850\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0202 - acc: 0.6850 - precision: 0.6883 - recall: 0.6850 - fscore: 0.6866\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0202 - acc: 0.6850 - precision: 0.6894 - recall: 0.6850 - fscore: 0.6871\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0202 - acc: 0.6850 - precision: 0.6889 - recall: 0.6850 - fscore: 0.6868\n",
      "testing\n",
      "100/100 [==============================] - 5s 46ms/step\n",
      "[0.02413589912466705, 0.6200000017881393, 0.6166666716337204, 0.610000005364418, 0.6131579160690308]\n",
      "pos: False\ttfidf: False\tner: True\tdpath: False\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.0267 - acc: 0.5500 - precision: 0.3175 - recall: 0.2200 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0192 - acc: 0.6400 - precision: 0.6829 - recall: 0.5100 - fscore: 0.5761\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0174 - acc: 0.6600 - precision: 0.7281 - recall: 0.5750 - fscore: 0.6371\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0162 - acc: 0.6800 - precision: 0.7548 - recall: 0.5650 - fscore: 0.6400\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0153 - acc: 0.6900 - precision: 0.7694 - recall: 0.6300 - fscore: 0.6862\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0127 - acc: 0.7200 - precision: 0.8816 - recall: 0.6450 - fscore: 0.7350\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0107 - acc: 0.7600 - precision: 0.8749 - recall: 0.7100 - fscore: 0.7792\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0090 - acc: 0.8050 - precision: 0.9209 - recall: 0.7550 - fscore: 0.8262\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0059 - acc: 0.8850 - precision: 0.9387 - recall: 0.8450 - fscore: 0.8875\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0049 - acc: 0.9100 - precision: 0.9228 - recall: 0.8950 - fscore: 0.9082\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0063 - acc: 0.8900 - precision: 0.9044 - recall: 0.8800 - fscore: 0.8916\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0052 - acc: 0.9150 - precision: 0.9183 - recall: 0.9050 - fscore: 0.9113\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0035 - acc: 0.9450 - precision: 0.9450 - recall: 0.9450 - fscore: 0.9450\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0037 - acc: 0.9300 - precision: 0.9350 - recall: 0.9300 - fscore: 0.9324\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0036 - acc: 0.9350 - precision: 0.9394 - recall: 0.9350 - fscore: 0.9371\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0033 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0033 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0031 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0031 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0031 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0032 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0031 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0032 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0031 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0031 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0031 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0030 - acc: 0.9550 - precision: 0.9550 - recall: 0.9500 - fscore: 0.9524\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9600 - recall: 0.9550 - fscore: 0.9574\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0027 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9600 - recall: 0.9550 - fscore: 0.9574\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9600 - recall: 0.9550 - fscore: 0.9574\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9600 - recall: 0.9550 - fscore: 0.9574\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0032 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0032 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0029 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "testing\n",
      "100/100 [==============================] - 5s 50ms/step\n",
      "[0.026253604888916017, 0.5200000017881393, 0.5327777862548828, 0.4800000011920929, nan]\n",
      "pos: False\ttfidf: False\tner: False\tdpath: True\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.0249 - acc: 0.5300 - precision: 0.4706 - recall: 0.4050 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0223 - acc: 0.6400 - precision: 0.6397 - recall: 0.6300 - fscore: 0.6344\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0215 - acc: 0.6600 - precision: 0.6553 - recall: 0.6200 - fscore: 0.6359\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0202 - acc: 0.6700 - precision: 0.6719 - recall: 0.6550 - fscore: 0.6628\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0226 - acc: 0.6500 - precision: 0.6500 - recall: 0.6500 - fscore: 0.6500\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0226 - acc: 0.6500 - precision: 0.6500 - recall: 0.6500 - fscore: 0.6500\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0220 - acc: 0.6550 - precision: 0.6572 - recall: 0.6550 - fscore: 0.6561\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0210 - acc: 0.6550 - precision: 0.6633 - recall: 0.6500 - fscore: 0.6563\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0194 - acc: 0.6750 - precision: 0.6900 - recall: 0.6600 - fscore: 0.6738\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0187 - acc: 0.6900 - precision: 0.6928 - recall: 0.6800 - fscore: 0.6861\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0189 - acc: 0.7000 - precision: 0.7000 - recall: 0.7000 - fscore: 0.7000\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0182 - acc: 0.7100 - precision: 0.7144 - recall: 0.7100 - fscore: 0.7121\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0175 - acc: 0.7200 - precision: 0.7271 - recall: 0.7150 - fscore: 0.7205\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0175 - acc: 0.7250 - precision: 0.7260 - recall: 0.7100 - fscore: 0.7173\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0172 - acc: 0.7300 - precision: 0.7289 - recall: 0.7200 - fscore: 0.7242\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0189 - acc: 0.6950 - precision: 0.6928 - recall: 0.6900 - fscore: 0.6913\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0178 - acc: 0.7200 - precision: 0.7200 - recall: 0.7200 - fscore: 0.7200\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0177 - acc: 0.7150 - precision: 0.7189 - recall: 0.7150 - fscore: 0.7168\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0172 - acc: 0.7300 - precision: 0.7300 - recall: 0.7300 - fscore: 0.7300\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0169 - acc: 0.7300 - precision: 0.7300 - recall: 0.7300 - fscore: 0.7300\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0169 - acc: 0.7350 - precision: 0.7389 - recall: 0.7350 - fscore: 0.7368\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0172 - acc: 0.7300 - precision: 0.7300 - recall: 0.7300 - fscore: 0.7300\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0165 - acc: 0.7400 - precision: 0.7400 - recall: 0.7400 - fscore: 0.7400\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0164 - acc: 0.7400 - precision: 0.7400 - recall: 0.7400 - fscore: 0.7400\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0166 - acc: 0.7400 - precision: 0.7400 - recall: 0.7400 - fscore: 0.7400\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0165 - acc: 0.7350 - precision: 0.7350 - recall: 0.7350 - fscore: 0.7350\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0161 - acc: 0.7400 - precision: 0.7400 - recall: 0.7400 - fscore: 0.7400\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0164 - acc: 0.7400 - precision: 0.7400 - recall: 0.7400 - fscore: 0.7400\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0168 - acc: 0.7350 - precision: 0.7350 - recall: 0.7350 - fscore: 0.7350\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0163 - acc: 0.7400 - precision: 0.7439 - recall: 0.7400 - fscore: 0.7418\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0163 - acc: 0.7400 - precision: 0.7439 - recall: 0.7400 - fscore: 0.7418\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0163 - acc: 0.7400 - precision: 0.7400 - recall: 0.7400 - fscore: 0.7400\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0163 - acc: 0.7400 - precision: 0.7400 - recall: 0.7400 - fscore: 0.7400\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0161 - acc: 0.7400 - precision: 0.7433 - recall: 0.7400 - fscore: 0.7416\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0164 - acc: 0.7400 - precision: 0.7400 - recall: 0.7400 - fscore: 0.7400\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0166 - acc: 0.7300 - precision: 0.7339 - recall: 0.7300 - fscore: 0.7318\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0167 - acc: 0.7350 - precision: 0.7350 - recall: 0.7350 - fscore: 0.7350\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0161 - acc: 0.7350 - precision: 0.7428 - recall: 0.7350 - fscore: 0.7387\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0153 - acc: 0.7600 - precision: 0.7642 - recall: 0.7500 - fscore: 0.7565\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0161 - acc: 0.7350 - precision: 0.7350 - recall: 0.7350 - fscore: 0.7350\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0157 - acc: 0.7450 - precision: 0.7539 - recall: 0.7450 - fscore: 0.7492\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0161 - acc: 0.7450 - precision: 0.7472 - recall: 0.7400 - fscore: 0.7434\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0168 - acc: 0.7350 - precision: 0.7350 - recall: 0.7350 - fscore: 0.7350\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0170 - acc: 0.7300 - precision: 0.7283 - recall: 0.7250 - fscore: 0.7266\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0206 - acc: 0.6650 - precision: 0.6667 - recall: 0.6600 - fscore: 0.6632\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0175 - acc: 0.7250 - precision: 0.7256 - recall: 0.7150 - fscore: 0.7200\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0151 - acc: 0.7650 - precision: 0.7633 - recall: 0.7550 - fscore: 0.7589\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0155 - acc: 0.7550 - precision: 0.7594 - recall: 0.7550 - fscore: 0.7571\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0151 - acc: 0.7600 - precision: 0.7600 - recall: 0.7600 - fscore: 0.7600\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0155 - acc: 0.7550 - precision: 0.7544 - recall: 0.7450 - fscore: 0.7495\n",
      "testing\n",
      "100/100 [==============================] - 5s 52ms/step\n",
      "[0.024415760673582552, 0.6100000113248825, 0.608888903260231, 0.6000000149011612, 0.6042105436325074]\n",
      "pos: True\ttfidf: True\tner: False\tdpath: False\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 0.0235 - acc: 0.5800 - precision: 0.4835 - recall: 0.3850 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0207 - acc: 0.6050 - precision: 0.6421 - recall: 0.4950 - fscore: 0.5435\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0194 - acc: 0.6300 - precision: 0.7100 - recall: 0.5700 - fscore: 0.6284\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0176 - acc: 0.6350 - precision: 0.7197 - recall: 0.5700 - fscore: 0.6321\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0167 - acc: 0.6600 - precision: 0.7300 - recall: 0.6000 - fscore: 0.6516\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0154 - acc: 0.6550 - precision: 0.8072 - recall: 0.5800 - fscore: 0.6659\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0137 - acc: 0.6950 - precision: 0.8490 - recall: 0.6300 - fscore: 0.7165\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0122 - acc: 0.7100 - precision: 0.8614 - recall: 0.6650 - fscore: 0.7422\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0115 - acc: 0.7600 - precision: 0.8648 - recall: 0.6850 - fscore: 0.7559\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0098 - acc: 0.8000 - precision: 0.9161 - recall: 0.7200 - fscore: 0.8015\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0093 - acc: 0.7900 - precision: 0.8793 - recall: 0.7450 - fscore: 0.8033\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0085 - acc: 0.8200 - precision: 0.8959 - recall: 0.7500 - fscore: 0.8117\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0083 - acc: 0.8450 - precision: 0.8916 - recall: 0.7750 - fscore: 0.8262\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0092 - acc: 0.8350 - precision: 0.8454 - recall: 0.8000 - fscore: 0.8205\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0067 - acc: 0.8700 - precision: 0.9143 - recall: 0.8500 - fscore: 0.8793\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.0056 - acc: 0.8850 - precision: 0.9403 - recall: 0.8750 - fscore: 0.9051\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0047 - acc: 0.9100 - precision: 0.9444 - recall: 0.9050 - fscore: 0.9231\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0045 - acc: 0.9100 - precision: 0.9472 - recall: 0.9050 - fscore: 0.9247\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0042 - acc: 0.9150 - precision: 0.9622 - recall: 0.9050 - fscore: 0.9309\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9200 - precision: 0.9594 - recall: 0.9200 - fscore: 0.9384\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0042 - acc: 0.9150 - precision: 0.9394 - recall: 0.9150 - fscore: 0.9266\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0036 - acc: 0.9250 - precision: 0.9578 - recall: 0.9250 - fscore: 0.9402\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0036 - acc: 0.9300 - precision: 0.9544 - recall: 0.9250 - fscore: 0.9387\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0032 - acc: 0.9400 - precision: 0.9689 - recall: 0.9300 - fscore: 0.9481\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0032 - acc: 0.9400 - precision: 0.9539 - recall: 0.9350 - fscore: 0.9437\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0033 - acc: 0.9400 - precision: 0.9525 - recall: 0.9300 - fscore: 0.9401\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0035 - acc: 0.9350 - precision: 0.9444 - recall: 0.9250 - fscore: 0.9342\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0030 - acc: 0.9400 - precision: 0.9494 - recall: 0.9400 - fscore: 0.9445\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0032 - acc: 0.9500 - precision: 0.9589 - recall: 0.9450 - fscore: 0.9516\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0029 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0030 - acc: 0.9500 - precision: 0.9600 - recall: 0.9500 - fscore: 0.9547\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0030 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0029 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0029 - acc: 0.9500 - precision: 0.9600 - recall: 0.9500 - fscore: 0.9547\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0029 - acc: 0.9500 - precision: 0.9594 - recall: 0.9500 - fscore: 0.9545\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0029 - acc: 0.9500 - precision: 0.9544 - recall: 0.9500 - fscore: 0.9521\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0028 - acc: 0.9500 - precision: 0.9544 - recall: 0.9500 - fscore: 0.9521\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0028 - acc: 0.9500 - precision: 0.9550 - recall: 0.9500 - fscore: 0.9524\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0025 - acc: 0.9550 - precision: 0.9650 - recall: 0.9550 - fscore: 0.9597\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0027 - acc: 0.9550 - precision: 0.9600 - recall: 0.9550 - fscore: 0.9574\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0027 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0026 - acc: 0.9550 - precision: 0.9600 - recall: 0.9550 - fscore: 0.9574\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0027 - acc: 0.9550 - precision: 0.9594 - recall: 0.9550 - fscore: 0.9571\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0025 - acc: 0.9550 - precision: 0.9650 - recall: 0.9550 - fscore: 0.9597\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0026 - acc: 0.9550 - precision: 0.9600 - recall: 0.9550 - fscore: 0.9574\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0026 - acc: 0.9550 - precision: 0.9633 - recall: 0.9550 - fscore: 0.9589\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0026 - acc: 0.9550 - precision: 0.9600 - recall: 0.9550 - fscore: 0.9574\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0027 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9600 - recall: 0.9550 - fscore: 0.9574\n",
      "testing\n",
      "100/100 [==============================] - 5s 55ms/step\n",
      "[0.029619856923818588, 0.4400000020861626, 0.4195635005831718, 0.38000000789761545, 0.3982559598982334]\n",
      "pos: False\ttfidf: True\tner: True\tdpath: False\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 27s 136ms/step - loss: 0.0250 - acc: 0.5250 - precision: 0.4076 - recall: 0.2850 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0211 - acc: 0.6400 - precision: 0.6402 - recall: 0.5350 - fscore: 0.5788\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0190 - acc: 0.6300 - precision: 0.6716 - recall: 0.5650 - fscore: 0.6077\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0176 - acc: 0.6500 - precision: 0.6850 - recall: 0.5250 - fscore: 0.5845\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0170 - acc: 0.6850 - precision: 0.7669 - recall: 0.5300 - fscore: 0.6083\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0152 - acc: 0.6850 - precision: 0.7531 - recall: 0.5500 - fscore: 0.6260\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0130 - acc: 0.7350 - precision: 0.7964 - recall: 0.6750 - fscore: 0.7290\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0101 - acc: 0.8000 - precision: 0.8690 - recall: 0.7450 - fscore: 0.7989\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0079 - acc: 0.8400 - precision: 0.8929 - recall: 0.8200 - fscore: 0.8531\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0075 - acc: 0.8600 - precision: 0.8778 - recall: 0.8450 - fscore: 0.8605\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0067 - acc: 0.8900 - precision: 0.9022 - recall: 0.8550 - fscore: 0.8764\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0055 - acc: 0.9050 - precision: 0.9172 - recall: 0.9050 - fscore: 0.9108\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0057 - acc: 0.9000 - precision: 0.9094 - recall: 0.8950 - fscore: 0.9018\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0046 - acc: 0.9250 - precision: 0.9250 - recall: 0.9250 - fscore: 0.9250\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0045 - acc: 0.9300 - precision: 0.9300 - recall: 0.9300 - fscore: 0.9300\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0045 - acc: 0.9300 - precision: 0.9300 - recall: 0.9300 - fscore: 0.9300\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0048 - acc: 0.9250 - precision: 0.9250 - recall: 0.9250 - fscore: 0.9250\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0042 - acc: 0.9350 - precision: 0.9400 - recall: 0.9350 - fscore: 0.9374\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0045 - acc: 0.9300 - precision: 0.9300 - recall: 0.9300 - fscore: 0.9300\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0048 - acc: 0.9200 - precision: 0.9200 - recall: 0.9200 - fscore: 0.9200\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0040 - acc: 0.9350 - precision: 0.9394 - recall: 0.9350 - fscore: 0.9371\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0038 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9400 - precision: 0.9400 - recall: 0.9400 - fscore: 0.9400\n",
      "testing\n",
      "100/100 [==============================] - 6s 57ms/step\n",
      "[0.0268335722386837, 0.5500000014901161, 0.5416666701436043, 0.5300000041723252, 0.5353801369667053]\n",
      "pos: False\ttfidf: False\tner: True\tdpath: True\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 0.0240 - acc: 0.5800 - precision: 0.5387 - recall: 0.4650 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0218 - acc: 0.6400 - precision: 0.6479 - recall: 0.5900 - fscore: 0.6159\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0206 - acc: 0.6400 - precision: 0.6798 - recall: 0.5950 - fscore: 0.6321\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0197 - acc: 0.6550 - precision: 0.7044 - recall: 0.6250 - fscore: 0.6594\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0189 - acc: 0.6700 - precision: 0.6971 - recall: 0.6600 - fscore: 0.6772\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0196 - acc: 0.6400 - precision: 0.6759 - recall: 0.6000 - fscore: 0.6338\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0178 - acc: 0.6900 - precision: 0.7299 - recall: 0.6550 - fscore: 0.6889\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0174 - acc: 0.6850 - precision: 0.7393 - recall: 0.6600 - fscore: 0.6960\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0165 - acc: 0.7200 - precision: 0.7580 - recall: 0.6900 - fscore: 0.7200\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0153 - acc: 0.7200 - precision: 0.7501 - recall: 0.7050 - fscore: 0.7261\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0148 - acc: 0.7400 - precision: 0.7567 - recall: 0.7400 - fscore: 0.7479\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0139 - acc: 0.7700 - precision: 0.7818 - recall: 0.7500 - fscore: 0.7646\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0128 - acc: 0.7850 - precision: 0.8135 - recall: 0.7800 - fscore: 0.7954\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0125 - acc: 0.7950 - precision: 0.8182 - recall: 0.7850 - fscore: 0.8005\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0122 - acc: 0.8000 - precision: 0.8068 - recall: 0.7900 - fscore: 0.7978\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0121 - acc: 0.8000 - precision: 0.8128 - recall: 0.8000 - fscore: 0.8061\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0121 - acc: 0.8050 - precision: 0.8139 - recall: 0.8000 - fscore: 0.8066\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0121 - acc: 0.8100 - precision: 0.8100 - recall: 0.8100 - fscore: 0.8100\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0120 - acc: 0.8050 - precision: 0.8112 - recall: 0.8050 - fscore: 0.8078\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0120 - acc: 0.8050 - precision: 0.8144 - recall: 0.8050 - fscore: 0.8095\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0118 - acc: 0.8100 - precision: 0.8217 - recall: 0.8100 - fscore: 0.8155\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0118 - acc: 0.8100 - precision: 0.8260 - recall: 0.8100 - fscore: 0.8173\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0117 - acc: 0.8100 - precision: 0.8239 - recall: 0.8100 - fscore: 0.8166\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0118 - acc: 0.8100 - precision: 0.8239 - recall: 0.8100 - fscore: 0.8166\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0118 - acc: 0.8100 - precision: 0.8222 - recall: 0.8100 - fscore: 0.8158\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0117 - acc: 0.8150 - precision: 0.8222 - recall: 0.8100 - fscore: 0.8158\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0116 - acc: 0.8150 - precision: 0.8239 - recall: 0.8150 - fscore: 0.8192\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0115 - acc: 0.8200 - precision: 0.8200 - recall: 0.8200 - fscore: 0.8200\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0120 - acc: 0.8100 - precision: 0.8100 - recall: 0.8100 - fscore: 0.8100\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0120 - acc: 0.8100 - precision: 0.8094 - recall: 0.8050 - fscore: 0.8071\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0121 - acc: 0.8000 - precision: 0.7989 - recall: 0.7950 - fscore: 0.7968\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0118 - acc: 0.8100 - precision: 0.8139 - recall: 0.8100 - fscore: 0.8118\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0120 - acc: 0.8050 - precision: 0.8128 - recall: 0.8000 - fscore: 0.8061\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0120 - acc: 0.8100 - precision: 0.8144 - recall: 0.8100 - fscore: 0.8121\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0122 - acc: 0.8050 - precision: 0.8094 - recall: 0.8050 - fscore: 0.8071\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0122 - acc: 0.8050 - precision: 0.8083 - recall: 0.8050 - fscore: 0.8066\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0131 - acc: 0.7850 - precision: 0.7950 - recall: 0.7800 - fscore: 0.7871\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0118 - acc: 0.8100 - precision: 0.8100 - recall: 0.8100 - fscore: 0.8100\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0147 - acc: 0.7550 - precision: 0.7550 - recall: 0.7550 - fscore: 0.7550\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0119 - acc: 0.8100 - precision: 0.8100 - recall: 0.8100 - fscore: 0.8100\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0117 - acc: 0.8150 - precision: 0.8150 - recall: 0.8150 - fscore: 0.8150\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0114 - acc: 0.8200 - precision: 0.8200 - recall: 0.8200 - fscore: 0.8200\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0113 - acc: 0.8250 - precision: 0.8250 - recall: 0.8250 - fscore: 0.8250\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0129 - acc: 0.7850 - precision: 0.7839 - recall: 0.7800 - fscore: 0.7818\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0158 - acc: 0.7500 - precision: 0.7500 - recall: 0.7500 - fscore: 0.7500\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0141 - acc: 0.7750 - precision: 0.7750 - recall: 0.7750 - fscore: 0.7750\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0129 - acc: 0.7950 - precision: 0.7950 - recall: 0.7950 - fscore: 0.7950\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0126 - acc: 0.8050 - precision: 0.8050 - recall: 0.8050 - fscore: 0.8050\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0127 - acc: 0.7950 - precision: 0.7950 - recall: 0.7950 - fscore: 0.7950\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0109 - acc: 0.8300 - precision: 0.8300 - recall: 0.8300 - fscore: 0.8300\n",
      "testing\n",
      "100/100 [==============================] - 6s 60ms/step\n",
      "[0.02388147171586752, 0.620000010728836, 0.620000010728836, 0.620000010728836, 0.6200000226497651]\n",
      "pos: True\ttfidf: False\tner: False\tdpath: True\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.0239 - acc: 0.5650 - precision: 0.5112 - recall: 0.4000 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0201 - acc: 0.6300 - precision: 0.6668 - recall: 0.5800 - fscore: 0.6175\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0203 - acc: 0.6300 - precision: 0.6571 - recall: 0.5600 - fscore: 0.6006\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0216 - acc: 0.6150 - precision: 0.6338 - recall: 0.5950 - fscore: 0.6120\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0195 - acc: 0.6400 - precision: 0.6899 - recall: 0.5650 - fscore: 0.6191\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0183 - acc: 0.6500 - precision: 0.6946 - recall: 0.6000 - fscore: 0.6413\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0169 - acc: 0.6750 - precision: 0.7353 - recall: 0.6300 - fscore: 0.6765\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0160 - acc: 0.6850 - precision: 0.7449 - recall: 0.6100 - fscore: 0.6667\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0157 - acc: 0.7100 - precision: 0.7727 - recall: 0.6400 - fscore: 0.6937\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0150 - acc: 0.7200 - precision: 0.7708 - recall: 0.6800 - fscore: 0.7199\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0129 - acc: 0.7550 - precision: 0.8343 - recall: 0.7100 - fscore: 0.7626\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0124 - acc: 0.7300 - precision: 0.8107 - recall: 0.7150 - fscore: 0.7578\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0109 - acc: 0.8000 - precision: 0.8470 - recall: 0.7350 - fscore: 0.7834\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0095 - acc: 0.8100 - precision: 0.8750 - recall: 0.7750 - fscore: 0.8195\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0073 - acc: 0.8650 - precision: 0.9162 - recall: 0.8350 - fscore: 0.8716\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0071 - acc: 0.8750 - precision: 0.9189 - recall: 0.8650 - fscore: 0.8899\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0062 - acc: 0.8850 - precision: 0.8976 - recall: 0.8800 - fscore: 0.8881\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0061 - acc: 0.8900 - precision: 0.9033 - recall: 0.8850 - fscore: 0.8937\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0067 - acc: 0.8750 - precision: 0.8922 - recall: 0.8650 - fscore: 0.8779\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0069 - acc: 0.8750 - precision: 0.9071 - recall: 0.8650 - fscore: 0.8844\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0060 - acc: 0.8900 - precision: 0.9172 - recall: 0.8850 - fscore: 0.9003\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0055 - acc: 0.8900 - precision: 0.9310 - recall: 0.8850 - fscore: 0.9062\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0053 - acc: 0.9050 - precision: 0.9264 - recall: 0.9000 - fscore: 0.9123\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0050 - acc: 0.9050 - precision: 0.9211 - recall: 0.9050 - fscore: 0.9126\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0049 - acc: 0.9050 - precision: 0.9233 - recall: 0.9050 - fscore: 0.9137\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0047 - acc: 0.9100 - precision: 0.9478 - recall: 0.9050 - fscore: 0.9250\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0046 - acc: 0.9100 - precision: 0.9483 - recall: 0.9100 - fscore: 0.9279\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0045 - acc: 0.9100 - precision: 0.9300 - recall: 0.9100 - fscore: 0.9195\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0044 - acc: 0.9100 - precision: 0.9533 - recall: 0.9100 - fscore: 0.9302\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0041 - acc: 0.9150 - precision: 0.9539 - recall: 0.9100 - fscore: 0.9299\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0043 - acc: 0.9150 - precision: 0.9583 - recall: 0.9150 - fscore: 0.9352\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0041 - acc: 0.9200 - precision: 0.9500 - recall: 0.9200 - fscore: 0.9342\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0039 - acc: 0.9200 - precision: 0.9572 - recall: 0.9200 - fscore: 0.9376\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9200 - precision: 0.9589 - recall: 0.9200 - fscore: 0.9378\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0036 - acc: 0.9250 - precision: 0.9683 - recall: 0.9200 - fscore: 0.9426\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0035 - acc: 0.9300 - precision: 0.9637 - recall: 0.9200 - fscore: 0.9399\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0034 - acc: 0.9350 - precision: 0.9444 - recall: 0.9350 - fscore: 0.9395\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0033 - acc: 0.9350 - precision: 0.9644 - recall: 0.9350 - fscore: 0.9489\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0029 - acc: 0.9400 - precision: 0.9689 - recall: 0.9350 - fscore: 0.9508\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0029 - acc: 0.9400 - precision: 0.9744 - recall: 0.9400 - fscore: 0.9560\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0029 - acc: 0.9400 - precision: 0.9744 - recall: 0.9400 - fscore: 0.9560\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0029 - acc: 0.9400 - precision: 0.9644 - recall: 0.9400 - fscore: 0.9516\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0028 - acc: 0.9400 - precision: 0.9732 - recall: 0.9400 - fscore: 0.9555\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0028 - acc: 0.9400 - precision: 0.9733 - recall: 0.9400 - fscore: 0.9558\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0026 - acc: 0.9450 - precision: 0.9789 - recall: 0.9450 - fscore: 0.9611\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0027 - acc: 0.9450 - precision: 0.9650 - recall: 0.9450 - fscore: 0.9545\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0024 - acc: 0.9500 - precision: 0.9744 - recall: 0.9500 - fscore: 0.9616\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0021 - acc: 0.9600 - precision: 0.9844 - recall: 0.9550 - fscore: 0.9687\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0020 - acc: 0.9600 - precision: 0.9800 - recall: 0.9600 - fscore: 0.9692\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0021 - acc: 0.9550 - precision: 0.9794 - recall: 0.9550 - fscore: 0.9666\n",
      "testing\n",
      "100/100 [==============================] - 6s 62ms/step\n",
      "[0.024659843929111958, 0.5499999970197678, 0.5650000005960465, 0.5400000005960465, 0.5514035105705262]\n",
      "pos: True\ttfidf: False\tner: True\tdpath: False\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.0240 - acc: 0.5700 - precision: 0.3916 - recall: 0.3000 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0196 - acc: 0.6350 - precision: 0.6576 - recall: 0.6250 - fscore: 0.6397\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0186 - acc: 0.6450 - precision: 0.6944 - recall: 0.6000 - fscore: 0.6417\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0174 - acc: 0.6400 - precision: 0.7433 - recall: 0.5350 - fscore: 0.6001\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0155 - acc: 0.6600 - precision: 0.7834 - recall: 0.5850 - fscore: 0.6617\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0143 - acc: 0.6700 - precision: 0.8293 - recall: 0.6050 - fscore: 0.6917\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0135 - acc: 0.7000 - precision: 0.8349 - recall: 0.5950 - fscore: 0.6844\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0102 - acc: 0.7800 - precision: 0.9400 - recall: 0.6850 - fscore: 0.7836\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0080 - acc: 0.8250 - precision: 0.9460 - recall: 0.7600 - fscore: 0.8366\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0056 - acc: 0.8900 - precision: 0.9526 - recall: 0.8450 - fscore: 0.8923\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0038 - acc: 0.9300 - precision: 0.9615 - recall: 0.8950 - fscore: 0.9257\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0031 - acc: 0.9500 - precision: 0.9689 - recall: 0.9300 - fscore: 0.9484\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0045 - acc: 0.9050 - precision: 0.9222 - recall: 0.9050 - fscore: 0.9132\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0043 - acc: 0.9250 - precision: 0.9339 - recall: 0.9100 - fscore: 0.9210\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0040 - acc: 0.9300 - precision: 0.9394 - recall: 0.9200 - fscore: 0.9292\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0040 - acc: 0.9250 - precision: 0.9250 - recall: 0.9150 - fscore: 0.9197\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0044 - acc: 0.9200 - precision: 0.9282 - recall: 0.9150 - fscore: 0.9210\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0034 - acc: 0.9400 - precision: 0.9450 - recall: 0.9400 - fscore: 0.9424\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0030 - acc: 0.9500 - precision: 0.9500 - recall: 0.9500 - fscore: 0.9500\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0026 - acc: 0.9550 - precision: 0.9550 - recall: 0.9550 - fscore: 0.9550\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9600 - precision: 0.9650 - recall: 0.9600 - fscore: 0.9624\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0024 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0024 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0025 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0024 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0025 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0025 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0025 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0025 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0025 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0025 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0025 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0025 - acc: 0.9600 - precision: 0.9600 - recall: 0.9600 - fscore: 0.9600\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9600 - fscore: 0.9624\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "testing\n",
      "100/100 [==============================] - 6s 65ms/step\n",
      "[0.025930724665522577, 0.5200000107288361, 0.5344444572925567, 0.5000000104308129, 0.5157310217618942]\n",
      "pos: False\ttfidf: True\tner: False\tdpath: True\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0241 - acc: 0.5400 - precision: 0.4943 - recall: 0.4250 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0231 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0242 - acc: 0.6200 - precision: 0.6200 - recall: 0.6200 - fscore: 0.6200\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0232 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "testing\n",
      "100/100 [==============================] - 7s 67ms/step\n",
      "[0.025806451216340065, 0.6000000089406967, 0.6000000089406967, 0.6000000089406967, 0.6000000238418579]\n",
      "pos: True\ttfidf: True\tner: True\tdpath: False\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.0241 - acc: 0.6000 - precision: 0.5790 - recall: 0.3900 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0229 - acc: 0.6400 - precision: 0.6400 - recall: 0.6400 - fscore: 0.6400\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0206 - acc: 0.6500 - precision: 0.6708 - recall: 0.5650 - fscore: 0.6090\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0193 - acc: 0.6300 - precision: 0.6744 - recall: 0.6000 - fscore: 0.6299\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0188 - acc: 0.6400 - precision: 0.7114 - recall: 0.6100 - fscore: 0.6539\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0170 - acc: 0.7050 - precision: 0.7374 - recall: 0.5900 - fscore: 0.6501\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0158 - acc: 0.6850 - precision: 0.7661 - recall: 0.6200 - fscore: 0.6800\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0144 - acc: 0.7200 - precision: 0.8008 - recall: 0.6600 - fscore: 0.7147\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0138 - acc: 0.7600 - precision: 0.8104 - recall: 0.6850 - fscore: 0.7340\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0148 - acc: 0.7100 - precision: 0.7473 - recall: 0.6500 - fscore: 0.6914\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0128 - acc: 0.7450 - precision: 0.8262 - recall: 0.6800 - fscore: 0.7434\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0105 - acc: 0.7900 - precision: 0.8572 - recall: 0.7550 - fscore: 0.8004\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0096 - acc: 0.8100 - precision: 0.8836 - recall: 0.7900 - fscore: 0.8328\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0082 - acc: 0.8350 - precision: 0.9004 - recall: 0.8050 - fscore: 0.8470\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0073 - acc: 0.8500 - precision: 0.9193 - recall: 0.8500 - fscore: 0.8820\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0066 - acc: 0.8650 - precision: 0.9371 - recall: 0.8600 - fscore: 0.8922\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0063 - acc: 0.8700 - precision: 0.9483 - recall: 0.8450 - fscore: 0.8917\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0057 - acc: 0.8900 - precision: 0.9557 - recall: 0.8750 - fscore: 0.9096\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0055 - acc: 0.8900 - precision: 0.9321 - recall: 0.8850 - fscore: 0.9068\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0048 - acc: 0.9000 - precision: 0.9614 - recall: 0.8950 - fscore: 0.9254\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0044 - acc: 0.9050 - precision: 0.9539 - recall: 0.9050 - fscore: 0.9276\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0043 - acc: 0.9200 - precision: 0.9487 - recall: 0.9050 - fscore: 0.9255\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0040 - acc: 0.9200 - precision: 0.9683 - recall: 0.9150 - fscore: 0.9393\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0038 - acc: 0.9200 - precision: 0.9626 - recall: 0.9150 - fscore: 0.9373\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0037 - acc: 0.9250 - precision: 0.9576 - recall: 0.9250 - fscore: 0.9402\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0036 - acc: 0.9250 - precision: 0.9600 - recall: 0.9250 - fscore: 0.9413\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0034 - acc: 0.9300 - precision: 0.9565 - recall: 0.9300 - fscore: 0.9423\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0039 - acc: 0.9250 - precision: 0.9494 - recall: 0.9250 - fscore: 0.9366\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0033 - acc: 0.9400 - precision: 0.9550 - recall: 0.9350 - fscore: 0.9442\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0028 - acc: 0.9550 - precision: 0.9650 - recall: 0.9550 - fscore: 0.9597\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9600 - precision: 0.9650 - recall: 0.9600 - fscore: 0.9624\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0024 - acc: 0.9600 - precision: 0.9739 - recall: 0.9550 - fscore: 0.9639\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0020 - acc: 0.9650 - precision: 0.9744 - recall: 0.9650 - fscore: 0.9695\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0020 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0021 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0023 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0022 - acc: 0.9650 - precision: 0.9650 - recall: 0.9650 - fscore: 0.9650\n",
      "testing\n",
      "100/100 [==============================] - 7s 70ms/step\n",
      "[0.024695923645049335, 0.5600000098347664, 0.5716666758060456, 0.5400000050663948, 0.554853829741478]\n",
      "pos: False\ttfidf: True\tner: True\tdpath: True\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.0235 - acc: 0.5200 - precision: 0.4726 - recall: 0.3750 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0211 - acc: 0.5600 - precision: 0.5991 - recall: 0.4900 - fscore: nan\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0208 - acc: 0.6200 - precision: 0.6637 - recall: 0.5850 - fscore: 0.6199\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0204 - acc: 0.5600 - precision: 0.7338 - recall: 0.5050 - fscore: 0.5855\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0193 - acc: 0.6000 - precision: 0.7485 - recall: 0.5500 - fscore: 0.6225\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0213 - acc: 0.6500 - precision: 0.6663 - recall: 0.6400 - fscore: 0.6520\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0197 - acc: 0.6500 - precision: 0.6960 - recall: 0.6250 - fscore: 0.6572\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0186 - acc: 0.6700 - precision: 0.7184 - recall: 0.6250 - fscore: 0.6653\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0174 - acc: 0.6800 - precision: 0.7319 - recall: 0.6400 - fscore: 0.6782\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0164 - acc: 0.7000 - precision: 0.7560 - recall: 0.6250 - fscore: 0.6799\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0156 - acc: 0.7050 - precision: 0.7720 - recall: 0.6600 - fscore: 0.7095\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0145 - acc: 0.7150 - precision: 0.7847 - recall: 0.6600 - fscore: 0.7108\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0130 - acc: 0.7600 - precision: 0.7838 - recall: 0.7050 - fscore: 0.7396\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0111 - acc: 0.8100 - precision: 0.8485 - recall: 0.7800 - fscore: 0.8117\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0102 - acc: 0.8400 - precision: 0.8679 - recall: 0.8150 - fscore: 0.8396\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0095 - acc: 0.8550 - precision: 0.8561 - recall: 0.8350 - fscore: 0.8447\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0106 - acc: 0.8100 - precision: 0.8194 - recall: 0.8100 - fscore: 0.8145\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0096 - acc: 0.8400 - precision: 0.8467 - recall: 0.8250 - fscore: 0.8345\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0083 - acc: 0.8650 - precision: 0.8711 - recall: 0.8600 - fscore: 0.8653\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0082 - acc: 0.8700 - precision: 0.8694 - recall: 0.8650 - fscore: 0.8671\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0080 - acc: 0.8750 - precision: 0.8744 - recall: 0.8700 - fscore: 0.8721\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0083 - acc: 0.8650 - precision: 0.8644 - recall: 0.8600 - fscore: 0.8621\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0078 - acc: 0.8750 - precision: 0.8800 - recall: 0.8750 - fscore: 0.8774\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0076 - acc: 0.8800 - precision: 0.8833 - recall: 0.8800 - fscore: 0.8816\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.0076 - acc: 0.8800 - precision: 0.8833 - recall: 0.8800 - fscore: 0.8816\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0075 - acc: 0.8800 - precision: 0.8850 - recall: 0.8800 - fscore: 0.8824\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0077 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0076 - acc: 0.8800 - precision: 0.8839 - recall: 0.8800 - fscore: 0.8818\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0076 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0077 - acc: 0.8800 - precision: 0.8783 - recall: 0.8700 - fscore: 0.8739\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0076 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0075 - acc: 0.8850 - precision: 0.8850 - recall: 0.8850 - fscore: 0.8850\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0078 - acc: 0.8750 - precision: 0.8750 - recall: 0.8750 - fscore: 0.8750\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0081 - acc: 0.8750 - precision: 0.8744 - recall: 0.8650 - fscore: 0.8695\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0082 - acc: 0.8650 - precision: 0.8650 - recall: 0.8650 - fscore: 0.8650\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0083 - acc: 0.8650 - precision: 0.8650 - recall: 0.8650 - fscore: 0.8650\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0078 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0074 - acc: 0.8850 - precision: 0.8850 - recall: 0.8850 - fscore: 0.8850\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0077 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0074 - acc: 0.8850 - precision: 0.8850 - recall: 0.8850 - fscore: 0.8850\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0077 - acc: 0.8750 - precision: 0.8750 - recall: 0.8750 - fscore: 0.8750\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0074 - acc: 0.8850 - precision: 0.8850 - recall: 0.8850 - fscore: 0.8850\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0074 - acc: 0.8850 - precision: 0.8850 - recall: 0.8850 - fscore: 0.8850\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0074 - acc: 0.8850 - precision: 0.8850 - recall: 0.8850 - fscore: 0.8850\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0075 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0094 - acc: 0.8500 - precision: 0.8472 - recall: 0.8450 - fscore: 0.8461\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0141 - acc: 0.7550 - precision: 0.7676 - recall: 0.7550 - fscore: 0.7607\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0164 - acc: 0.7150 - precision: 0.7261 - recall: 0.7150 - fscore: 0.7203\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0119 - acc: 0.8050 - precision: 0.8050 - recall: 0.8050 - fscore: 0.8050\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0104 - acc: 0.8300 - precision: 0.8350 - recall: 0.8300 - fscore: 0.8324\n",
      "testing\n",
      "100/100 [==============================] - 7s 74ms/step\n",
      "[0.025552373472601177, 0.5800000071525574, 0.5833333432674408, 0.5700000047683715, 0.5763158023357391]\n",
      "pos: True\ttfidf: False\tner: True\tdpath: True\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 0.0256 - acc: 0.5650 - precision: 0.4898 - recall: 0.3150 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0203 - acc: 0.6450 - precision: 0.6391 - recall: 0.5500 - fscore: 0.5872\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0185 - acc: 0.6450 - precision: 0.6888 - recall: 0.5200 - fscore: 0.5810\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0171 - acc: 0.6650 - precision: 0.7240 - recall: 0.6100 - fscore: 0.6585\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0151 - acc: 0.6900 - precision: 0.7666 - recall: 0.6350 - fscore: 0.6892\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0131 - acc: 0.7300 - precision: 0.8159 - recall: 0.7000 - fscore: 0.7476\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0101 - acc: 0.8000 - precision: 0.8697 - recall: 0.7600 - fscore: 0.8092\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0093 - acc: 0.8300 - precision: 0.8518 - recall: 0.8050 - fscore: 0.8267\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0088 - acc: 0.8300 - precision: 0.8665 - recall: 0.8150 - fscore: 0.8389\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0093 - acc: 0.8400 - precision: 0.8475 - recall: 0.8400 - fscore: 0.8433\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0102 - acc: 0.8150 - precision: 0.8272 - recall: 0.8100 - fscore: 0.8182\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0094 - acc: 0.8350 - precision: 0.8389 - recall: 0.8300 - fscore: 0.8342\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0105 - acc: 0.8250 - precision: 0.8333 - recall: 0.8150 - fscore: 0.8237\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0087 - acc: 0.8550 - precision: 0.8601 - recall: 0.8450 - fscore: 0.8520\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0087 - acc: 0.8600 - precision: 0.8600 - recall: 0.8600 - fscore: 0.8600\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0080 - acc: 0.8600 - precision: 0.8667 - recall: 0.8550 - fscore: 0.8605\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0083 - acc: 0.8600 - precision: 0.8600 - recall: 0.8600 - fscore: 0.8600\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0076 - acc: 0.8750 - precision: 0.8750 - recall: 0.8750 - fscore: 0.8750\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0072 - acc: 0.8800 - precision: 0.8844 - recall: 0.8800 - fscore: 0.8821\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0077 - acc: 0.8750 - precision: 0.8750 - recall: 0.8750 - fscore: 0.8750\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0074 - acc: 0.8750 - precision: 0.8844 - recall: 0.8750 - fscore: 0.8795\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0074 - acc: 0.8800 - precision: 0.8850 - recall: 0.8800 - fscore: 0.8824\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0075 - acc: 0.8800 - precision: 0.8833 - recall: 0.8750 - fscore: 0.8789\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0075 - acc: 0.8800 - precision: 0.8839 - recall: 0.8800 - fscore: 0.8818\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0074 - acc: 0.8800 - precision: 0.8833 - recall: 0.8800 - fscore: 0.8816\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0074 - acc: 0.8800 - precision: 0.8833 - recall: 0.8800 - fscore: 0.8816\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0072 - acc: 0.8800 - precision: 0.8844 - recall: 0.8800 - fscore: 0.8821\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0074 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0071 - acc: 0.8800 - precision: 0.8850 - recall: 0.8800 - fscore: 0.8824\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0071 - acc: 0.8800 - precision: 0.8889 - recall: 0.8800 - fscore: 0.8842\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0076 - acc: 0.8750 - precision: 0.8750 - recall: 0.8750 - fscore: 0.8750\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0082 - acc: 0.8650 - precision: 0.8733 - recall: 0.8650 - fscore: 0.8689\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0085 - acc: 0.8600 - precision: 0.8600 - recall: 0.8600 - fscore: 0.8600\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0078 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0073 - acc: 0.8750 - precision: 0.8783 - recall: 0.8750 - fscore: 0.8766\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0075 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0073 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0075 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0072 - acc: 0.8850 - precision: 0.8900 - recall: 0.8850 - fscore: 0.8874\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0071 - acc: 0.8850 - precision: 0.8900 - recall: 0.8850 - fscore: 0.8874\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0071 - acc: 0.8850 - precision: 0.8850 - recall: 0.8850 - fscore: 0.8850\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0072 - acc: 0.8850 - precision: 0.8894 - recall: 0.8850 - fscore: 0.8871\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0068 - acc: 0.8900 - precision: 0.8950 - recall: 0.8900 - fscore: 0.8924\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0068 - acc: 0.8900 - precision: 0.8950 - recall: 0.8900 - fscore: 0.8924\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0068 - acc: 0.8900 - precision: 0.8900 - recall: 0.8900 - fscore: 0.8900\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0068 - acc: 0.8900 - precision: 0.8939 - recall: 0.8900 - fscore: 0.8918\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0068 - acc: 0.8900 - precision: 0.8900 - recall: 0.8900 - fscore: 0.8900\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0068 - acc: 0.8900 - precision: 0.8950 - recall: 0.8900 - fscore: 0.8924\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0069 - acc: 0.8900 - precision: 0.8900 - recall: 0.8900 - fscore: 0.8900\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0069 - acc: 0.8900 - precision: 0.8900 - recall: 0.8900 - fscore: 0.8900\n",
      "testing\n",
      "100/100 [==============================] - 8s 75ms/step\n",
      "[0.02461017658933997, 0.5600000098347664, 0.5780555680394173, 0.5600000098347664, 0.5681871563196182]\n",
      "pos: True\ttfidf: True\tner: False\tdpath: True\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.0235 - acc: 0.5700 - precision: 0.5002 - recall: 0.4050 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0211 - acc: 0.6350 - precision: 0.6303 - recall: 0.6050 - fscore: 0.6166\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0198 - acc: 0.6350 - precision: 0.6971 - recall: 0.5750 - fscore: 0.6277\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0196 - acc: 0.6350 - precision: 0.6835 - recall: 0.5700 - fscore: 0.6169\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0189 - acc: 0.6600 - precision: 0.6738 - recall: 0.6000 - fscore: 0.6288\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0152 - acc: 0.6950 - precision: 0.7882 - recall: 0.6250 - fscore: 0.6886\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0137 - acc: 0.7100 - precision: 0.7857 - recall: 0.6650 - fscore: 0.7152\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0112 - acc: 0.7650 - precision: 0.8437 - recall: 0.7150 - fscore: 0.7703\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0096 - acc: 0.8150 - precision: 0.8712 - recall: 0.7800 - fscore: 0.8214\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0084 - acc: 0.8500 - precision: 0.8910 - recall: 0.8100 - fscore: 0.8474\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0077 - acc: 0.8600 - precision: 0.8890 - recall: 0.8400 - fscore: 0.8620\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0073 - acc: 0.8750 - precision: 0.9006 - recall: 0.8600 - fscore: 0.8792\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0067 - acc: 0.8850 - precision: 0.9114 - recall: 0.8750 - fscore: 0.8917\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0062 - acc: 0.9000 - precision: 0.9033 - recall: 0.8850 - fscore: 0.8937\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0068 - acc: 0.8850 - precision: 0.8875 - recall: 0.8750 - fscore: 0.8807\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0064 - acc: 0.8900 - precision: 0.8944 - recall: 0.8900 - fscore: 0.8921\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0059 - acc: 0.9050 - precision: 0.9100 - recall: 0.9050 - fscore: 0.9074\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0061 - acc: 0.9050 - precision: 0.9050 - recall: 0.9050 - fscore: 0.9050\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0059 - acc: 0.9050 - precision: 0.9094 - recall: 0.9050 - fscore: 0.9071\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0060 - acc: 0.9050 - precision: 0.9050 - recall: 0.9050 - fscore: 0.9050\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0063 - acc: 0.8950 - precision: 0.9050 - recall: 0.8950 - fscore: 0.8994\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0063 - acc: 0.8950 - precision: 0.9000 - recall: 0.8950 - fscore: 0.8974\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0058 - acc: 0.9100 - precision: 0.9100 - recall: 0.9100 - fscore: 0.9100\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0058 - acc: 0.9100 - precision: 0.9100 - recall: 0.9100 - fscore: 0.9100\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0062 - acc: 0.9000 - precision: 0.9000 - recall: 0.8950 - fscore: 0.8974\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0059 - acc: 0.9050 - precision: 0.9050 - recall: 0.9050 - fscore: 0.9050\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0061 - acc: 0.9050 - precision: 0.9050 - recall: 0.9050 - fscore: 0.9050\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0061 - acc: 0.9000 - precision: 0.9000 - recall: 0.9000 - fscore: 0.9000\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0061 - acc: 0.9000 - precision: 0.9000 - recall: 0.9000 - fscore: 0.9000\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0060 - acc: 0.9050 - precision: 0.9050 - recall: 0.9050 - fscore: 0.9050\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0080 - acc: 0.8700 - precision: 0.8700 - recall: 0.8700 - fscore: 0.8700\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0067 - acc: 0.8900 - precision: 0.8900 - recall: 0.8900 - fscore: 0.8900\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0069 - acc: 0.8850 - precision: 0.8850 - recall: 0.8850 - fscore: 0.8850\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0078 - acc: 0.8750 - precision: 0.8744 - recall: 0.8650 - fscore: 0.8695\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0092 - acc: 0.8450 - precision: 0.8450 - recall: 0.8450 - fscore: 0.8450\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0074 - acc: 0.8800 - precision: 0.8800 - recall: 0.8800 - fscore: 0.8800\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0078 - acc: 0.8750 - precision: 0.8750 - recall: 0.8750 - fscore: 0.8750\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0065 - acc: 0.8950 - precision: 0.8950 - recall: 0.8950 - fscore: 0.8950\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0065 - acc: 0.9000 - precision: 0.9000 - recall: 0.9000 - fscore: 0.9000\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0060 - acc: 0.9050 - precision: 0.9050 - recall: 0.9050 - fscore: 0.9050\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0064 - acc: 0.9000 - precision: 0.9000 - recall: 0.9000 - fscore: 0.9000\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0061 - acc: 0.9050 - precision: 0.9050 - recall: 0.9050 - fscore: 0.9050\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0061 - acc: 0.9050 - precision: 0.9050 - recall: 0.9050 - fscore: 0.9050\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0061 - acc: 0.9050 - precision: 0.9050 - recall: 0.9050 - fscore: 0.9050\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0057 - acc: 0.9100 - precision: 0.9100 - recall: 0.9100 - fscore: 0.9100\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0065 - acc: 0.8950 - precision: 0.8950 - recall: 0.8950 - fscore: 0.8950\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0062 - acc: 0.8950 - precision: 0.8994 - recall: 0.8950 - fscore: 0.8971\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0059 - acc: 0.9050 - precision: 0.9050 - recall: 0.9050 - fscore: 0.9050\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0058 - acc: 0.9100 - precision: 0.9100 - recall: 0.9100 - fscore: 0.9100\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0056 - acc: 0.9100 - precision: 0.9100 - recall: 0.9100 - fscore: 0.9100\n",
      "testing\n",
      "100/100 [==============================] - 8s 77ms/step\n",
      "[0.02872022669762373, 0.5000000059604645, 0.5000000059604645, 0.49000000655651094, 0.4947368621826172]\n",
      "pos: True\ttfidf: True\tner: True\tdpath: True\tmatching: False\n",
      "\n",
      "generating batch...\n",
      "\n",
      " 300 of 300 processing...training...\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.0226 - acc: 0.6050 - precision: 0.5643 - recall: 0.4250 - fscore: nan\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0226 - acc: 0.6000 - precision: 0.6021 - recall: 0.5900 - fscore: 0.5956\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0193 - acc: 0.6350 - precision: 0.7042 - recall: 0.5750 - fscore: 0.6279\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0193 - acc: 0.6600 - precision: 0.6977 - recall: 0.6300 - fscore: 0.6610\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0178 - acc: 0.6750 - precision: 0.7484 - recall: 0.6400 - fscore: 0.6856\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0176 - acc: 0.6700 - precision: 0.7174 - recall: 0.6250 - fscore: 0.6663\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0180 - acc: 0.6750 - precision: 0.7394 - recall: 0.6400 - fscore: 0.6837\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0171 - acc: 0.6800 - precision: 0.7260 - recall: 0.6550 - fscore: 0.6865\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0162 - acc: 0.6950 - precision: 0.7496 - recall: 0.6400 - fscore: 0.6874\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0155 - acc: 0.6950 - precision: 0.7537 - recall: 0.6500 - fscore: 0.6952\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0130 - acc: 0.7700 - precision: 0.8200 - recall: 0.7400 - fscore: 0.7769\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0127 - acc: 0.7650 - precision: 0.8021 - recall: 0.7300 - fscore: 0.7615\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0114 - acc: 0.7900 - precision: 0.8356 - recall: 0.7750 - fscore: 0.8027\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0110 - acc: 0.8050 - precision: 0.8553 - recall: 0.7550 - fscore: 0.7994\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0109 - acc: 0.8000 - precision: 0.8288 - recall: 0.7750 - fscore: 0.7996\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0099 - acc: 0.8100 - precision: 0.8678 - recall: 0.7950 - fscore: 0.8272\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0088 - acc: 0.8450 - precision: 0.8686 - recall: 0.8050 - fscore: 0.8339\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0079 - acc: 0.8600 - precision: 0.8861 - recall: 0.8400 - fscore: 0.8609\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0072 - acc: 0.8700 - precision: 0.8950 - recall: 0.8550 - fscore: 0.8739\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0064 - acc: 0.8900 - precision: 0.9108 - recall: 0.8800 - fscore: 0.8941\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0064 - acc: 0.8850 - precision: 0.9117 - recall: 0.8750 - fscore: 0.8921\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0056 - acc: 0.9000 - precision: 0.9228 - recall: 0.8950 - fscore: 0.9082\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0055 - acc: 0.9050 - precision: 0.9089 - recall: 0.8950 - fscore: 0.9016\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0049 - acc: 0.9100 - precision: 0.9372 - recall: 0.9100 - fscore: 0.9229\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0051 - acc: 0.9000 - precision: 0.9271 - recall: 0.9000 - fscore: 0.9126\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0053 - acc: 0.9050 - precision: 0.9283 - recall: 0.9000 - fscore: 0.9131\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0049 - acc: 0.9100 - precision: 0.9378 - recall: 0.9100 - fscore: 0.9232\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0047 - acc: 0.9150 - precision: 0.9417 - recall: 0.9150 - fscore: 0.9276\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0046 - acc: 0.9150 - precision: 0.9369 - recall: 0.9150 - fscore: 0.9252\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0043 - acc: 0.9250 - precision: 0.9433 - recall: 0.9250 - fscore: 0.9337\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0045 - acc: 0.9200 - precision: 0.9389 - recall: 0.9200 - fscore: 0.9289\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0043 - acc: 0.9250 - precision: 0.9383 - recall: 0.9250 - fscore: 0.9313\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0041 - acc: 0.9250 - precision: 0.9383 - recall: 0.9250 - fscore: 0.9313\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0043 - acc: 0.9250 - precision: 0.9250 - recall: 0.9250 - fscore: 0.9250\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0047 - acc: 0.9150 - precision: 0.9200 - recall: 0.9150 - fscore: 0.9174\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0048 - acc: 0.9200 - precision: 0.9294 - recall: 0.9200 - fscore: 0.9245\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0047 - acc: 0.9200 - precision: 0.9344 - recall: 0.9200 - fscore: 0.9268\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0041 - acc: 0.9300 - precision: 0.9450 - recall: 0.9300 - fscore: 0.9371\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0041 - acc: 0.9300 - precision: 0.9400 - recall: 0.9300 - fscore: 0.9347\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.0040 - acc: 0.9300 - precision: 0.9444 - recall: 0.9300 - fscore: 0.9368\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0041 - acc: 0.9300 - precision: 0.9394 - recall: 0.9300 - fscore: 0.9345\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0037 - acc: 0.9350 - precision: 0.9539 - recall: 0.9350 - fscore: 0.9439\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0038 - acc: 0.9350 - precision: 0.9450 - recall: 0.9350 - fscore: 0.9397\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0039 - acc: 0.9350 - precision: 0.9425 - recall: 0.9300 - fscore: 0.9357\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0038 - acc: 0.9350 - precision: 0.9394 - recall: 0.9350 - fscore: 0.9371\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0038 - acc: 0.9350 - precision: 0.9489 - recall: 0.9350 - fscore: 0.9416\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.0039 - acc: 0.9350 - precision: 0.9444 - recall: 0.9350 - fscore: 0.9395\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9350 - precision: 0.9444 - recall: 0.9350 - fscore: 0.9395\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9350 - precision: 0.9350 - recall: 0.9350 - fscore: 0.9350\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.0039 - acc: 0.9350 - precision: 0.9444 - recall: 0.9350 - fscore: 0.9395\n",
      "testing\n",
      "100/100 [==============================] - 8s 82ms/step\n",
      "[0.025438963901251554, 0.5400000020861626, 0.5655555605888367, 0.5400000020861626, 0.5507894873619079]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "use_matching = False\n",
    "\n",
    "# These represent the possible feature configs\n",
    "permutations= [[True, False, False, False],\n",
    "               [False, True, False, False],\n",
    "               [False, False, True, False],\n",
    "               [False, False, False, True],\n",
    "               [True, True, False, False],\n",
    "               [False, True, True, False],\n",
    "               [False, False, True, True],\n",
    "               [True, False, False, True],\n",
    "               [True, False, True, False],\n",
    "               [False, True, False, True],\n",
    "               [True, True, True, False],\n",
    "               [False, True, True, True],\n",
    "               [True, False, True, True],\n",
    "               [True, True, False, True],\n",
    "               [True, True, True, True]]\n",
    "\n",
    "for p in permutations:\n",
    "    # Unpack feature config\n",
    "    use_pos, use_tfidf, use_ner, use_dpath = p\n",
    "    \n",
    "    print('pos: {}\\ttfidf: {}\\tner: {}\\tdpath: {}\\tmatching: {}\\n'.format(use_pos, use_tfidf, use_ner, use_dpath, use_matching))\n",
    "    print('generating batch...\\n')\n",
    "    document_batch, question_batch, answer_batch = generate_batch(train_dataset[:300])\n",
    "    \n",
    "    # Train\n",
    "    print('training...\\n')\n",
    "    model = create_model(document_batch.shape[2], answer_batch.shape[1], document_batch.shape[1], question_batch.shape[1])\n",
    "    train_model(model, document_batch[:200], question_batch[:200], answer_batch[:200], 50)\n",
    "    \n",
    "    # Test\n",
    "    print('testing')\n",
    "    print(model.evaluate([document_batch[200:], question_batch[200:]], [answer_batch[200:]], batch_size=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IOW10rFlEcD"
   },
   "source": [
    "### 2.3.2 Full Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GSTn8WeamfC"
   },
   "source": [
    "#### 2.3.2.1 Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3607
    },
    "colab_type": "code",
    "id": "nQ94zda2TwJ1",
    "outputId": "faac99f0-ff64-452a-9676-1892249beb0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 750 of 750 processing...WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "650/650 [==============================] - 66s 102ms/step - loss: 0.0235 - acc: 0.5692 - precision: 0.6019 - recall: 0.4646 - fscore: nan\n",
      "Epoch 2/100\n",
      "650/650 [==============================] - 62s 95ms/step - loss: 0.0207 - acc: 0.6092 - precision: 0.6573 - recall: 0.5354 - fscore: 0.5844\n",
      "Epoch 3/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0186 - acc: 0.6400 - precision: 0.6891 - recall: 0.5569 - fscore: 0.6107\n",
      "Epoch 4/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0170 - acc: 0.6646 - precision: 0.7353 - recall: 0.5769 - fscore: 0.6406\n",
      "Epoch 5/100\n",
      "650/650 [==============================] - 62s 95ms/step - loss: 0.0151 - acc: 0.6877 - precision: 0.7742 - recall: 0.6169 - fscore: 0.6831\n",
      "Epoch 6/100\n",
      "650/650 [==============================] - 63s 96ms/step - loss: 0.0138 - acc: 0.7077 - precision: 0.7942 - recall: 0.6446 - fscore: 0.7055\n",
      "Epoch 7/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0124 - acc: 0.7492 - precision: 0.8189 - recall: 0.6954 - fscore: 0.7480\n",
      "Epoch 8/100\n",
      "650/650 [==============================] - 62s 95ms/step - loss: 0.0103 - acc: 0.7862 - precision: 0.8733 - recall: 0.7369 - fscore: 0.7951\n",
      "Epoch 9/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0091 - acc: 0.8169 - precision: 0.8787 - recall: 0.7708 - fscore: 0.8186\n",
      "Epoch 10/100\n",
      "650/650 [==============================] - 63s 96ms/step - loss: 0.0090 - acc: 0.8292 - precision: 0.8618 - recall: 0.7938 - fscore: 0.8248\n",
      "Epoch 11/100\n",
      "650/650 [==============================] - 63s 96ms/step - loss: 0.0080 - acc: 0.8477 - precision: 0.8887 - recall: 0.8262 - fscore: 0.8549\n",
      "Epoch 12/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0082 - acc: 0.8492 - precision: 0.8748 - recall: 0.8308 - fscore: 0.8504\n",
      "Epoch 13/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0066 - acc: 0.8769 - precision: 0.9019 - recall: 0.8554 - fscore: 0.8769\n",
      "Epoch 14/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0062 - acc: 0.8877 - precision: 0.9092 - recall: 0.8800 - fscore: 0.8935\n",
      "Epoch 15/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0058 - acc: 0.9015 - precision: 0.9143 - recall: 0.8923 - fscore: 0.9026\n",
      "Epoch 16/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0057 - acc: 0.9000 - precision: 0.9094 - recall: 0.8938 - fscore: 0.9011\n",
      "Epoch 17/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0055 - acc: 0.9046 - precision: 0.9162 - recall: 0.9046 - fscore: 0.9101\n",
      "Epoch 18/100\n",
      "650/650 [==============================] - 63s 96ms/step - loss: 0.0055 - acc: 0.9108 - precision: 0.9196 - recall: 0.9031 - fscore: 0.9107\n",
      "Epoch 19/100\n",
      "650/650 [==============================] - 63s 98ms/step - loss: 0.0053 - acc: 0.9108 - precision: 0.9162 - recall: 0.9092 - fscore: 0.9126\n",
      "Epoch 20/100\n",
      "650/650 [==============================] - 62s 95ms/step - loss: 0.0053 - acc: 0.9123 - precision: 0.9179 - recall: 0.9108 - fscore: 0.9141\n",
      "Epoch 21/100\n",
      "650/650 [==============================] - 62s 95ms/step - loss: 0.0053 - acc: 0.9138 - precision: 0.9178 - recall: 0.9108 - fscore: 0.9141\n",
      "Epoch 22/100\n",
      "650/650 [==============================] - 62s 95ms/step - loss: 0.0051 - acc: 0.9138 - precision: 0.9221 - recall: 0.9138 - fscore: 0.9177\n",
      "Epoch 23/100\n",
      "650/650 [==============================] - 62s 95ms/step - loss: 0.0049 - acc: 0.9185 - precision: 0.9243 - recall: 0.9185 - fscore: 0.9212\n",
      "Epoch 24/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0049 - acc: 0.9185 - precision: 0.9238 - recall: 0.9169 - fscore: 0.9202\n",
      "Epoch 25/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0047 - acc: 0.9231 - precision: 0.9275 - recall: 0.9231 - fscore: 0.9252\n",
      "Epoch 26/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0047 - acc: 0.9215 - precision: 0.9268 - recall: 0.9215 - fscore: 0.9240\n",
      "Epoch 27/100\n",
      "650/650 [==============================] - 63s 96ms/step - loss: 0.0049 - acc: 0.9200 - precision: 0.9220 - recall: 0.9169 - fscore: 0.9192\n",
      "Epoch 28/100\n",
      "650/650 [==============================] - 63s 96ms/step - loss: 0.0048 - acc: 0.9215 - precision: 0.9215 - recall: 0.9215 - fscore: 0.9215\n",
      "Epoch 29/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0050 - acc: 0.9185 - precision: 0.9198 - recall: 0.9185 - fscore: 0.9191\n",
      "Epoch 30/100\n",
      "650/650 [==============================] - 63s 96ms/step - loss: 0.0057 - acc: 0.9000 - precision: 0.9083 - recall: 0.8969 - fscore: 0.9022\n",
      "Epoch 31/100\n",
      "650/650 [==============================] - 63s 96ms/step - loss: 0.0067 - acc: 0.8769 - precision: 0.8791 - recall: 0.8723 - fscore: 0.8755\n",
      "Epoch 32/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0068 - acc: 0.8800 - precision: 0.8827 - recall: 0.8800 - fscore: 0.8813\n",
      "Epoch 33/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0060 - acc: 0.8969 - precision: 0.9009 - recall: 0.8954 - fscore: 0.8980\n",
      "Epoch 34/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0056 - acc: 0.9015 - precision: 0.9055 - recall: 0.9015 - fscore: 0.9034\n",
      "Epoch 35/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0047 - acc: 0.9246 - precision: 0.9242 - recall: 0.9215 - fscore: 0.9227\n",
      "Epoch 36/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0050 - acc: 0.9169 - precision: 0.9169 - recall: 0.9169 - fscore: 0.9169\n",
      "Epoch 37/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0053 - acc: 0.9092 - precision: 0.9123 - recall: 0.9077 - fscore: 0.9099\n",
      "Epoch 38/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0050 - acc: 0.9200 - precision: 0.9198 - recall: 0.9185 - fscore: 0.9191\n",
      "Epoch 39/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0046 - acc: 0.9277 - precision: 0.9277 - recall: 0.9277 - fscore: 0.9277\n",
      "Epoch 40/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0047 - acc: 0.9231 - precision: 0.9231 - recall: 0.9231 - fscore: 0.9231\n",
      "Epoch 41/100\n",
      "650/650 [==============================] - 63s 98ms/step - loss: 0.0047 - acc: 0.9262 - precision: 0.9262 - recall: 0.9262 - fscore: 0.9262\n",
      "Epoch 42/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0046 - acc: 0.9292 - precision: 0.9292 - recall: 0.9292 - fscore: 0.9292\n",
      "Epoch 43/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0045 - acc: 0.9277 - precision: 0.9277 - recall: 0.9277 - fscore: 0.9277\n",
      "Epoch 44/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 45/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 46/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 47/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 48/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9320 - recall: 0.9308 - fscore: 0.9313\n",
      "Epoch 49/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 50/100\n",
      "650/650 [==============================] - 65s 99ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 51/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 52/100\n",
      "650/650 [==============================] - 65s 99ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9321 - recall: 0.9308 - fscore: 0.9314\n",
      "Epoch 53/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0046 - acc: 0.9292 - precision: 0.9292 - recall: 0.9292 - fscore: 0.9292\n",
      "Epoch 54/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 55/100\n",
      "650/650 [==============================] - 66s 102ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 56/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 57/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 58/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 59/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0045 - acc: 0.9292 - precision: 0.9292 - recall: 0.9292 - fscore: 0.9292\n",
      "Epoch 60/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 61/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 62/100\n",
      "650/650 [==============================] - 63s 96ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 63/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 64/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 65/100\n",
      "650/650 [==============================] - 62s 96ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 66/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0045 - acc: 0.9292 - precision: 0.9292 - recall: 0.9292 - fscore: 0.9292\n",
      "Epoch 67/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 68/100\n",
      "650/650 [==============================] - 64s 99ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 69/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 70/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 71/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 72/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 73/100\n",
      "650/650 [==============================] - 63s 98ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 74/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 75/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 76/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 77/100\n",
      "650/650 [==============================] - 66s 101ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 78/100\n",
      "650/650 [==============================] - 66s 101ms/step - loss: 0.0044 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 79/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 80/100\n",
      "650/650 [==============================] - 65s 99ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 81/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 82/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 83/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 84/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 85/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 86/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 87/100\n",
      "650/650 [==============================] - 63s 96ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 88/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 89/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0045 - acc: 0.9308 - precision: 0.9308 - recall: 0.9308 - fscore: 0.9308\n",
      "Epoch 90/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0045 - acc: 0.9292 - precision: 0.9292 - recall: 0.9292 - fscore: 0.9292\n",
      "Epoch 91/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0094 - acc: 0.8338 - precision: 0.8391 - recall: 0.8323 - fscore: 0.8355\n",
      "Epoch 92/100\n",
      "650/650 [==============================] - 65s 101ms/step - loss: 0.0098 - acc: 0.8308 - precision: 0.8342 - recall: 0.8292 - fscore: 0.8316\n",
      "Epoch 93/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0091 - acc: 0.8492 - precision: 0.8538 - recall: 0.8492 - fscore: 0.8514\n",
      "Epoch 94/100\n",
      "650/650 [==============================] - 66s 102ms/step - loss: 0.0084 - acc: 0.8569 - precision: 0.8576 - recall: 0.8554 - fscore: 0.8564\n",
      "Epoch 95/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0069 - acc: 0.8892 - precision: 0.8892 - recall: 0.8892 - fscore: 0.8892\n",
      "Epoch 96/100\n",
      "650/650 [==============================] - 65s 100ms/step - loss: 0.0060 - acc: 0.9062 - precision: 0.9062 - recall: 0.9062 - fscore: 0.9062\n",
      "Epoch 97/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0053 - acc: 0.9154 - precision: 0.9154 - recall: 0.9154 - fscore: 0.9154\n",
      "Epoch 98/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0052 - acc: 0.9169 - precision: 0.9169 - recall: 0.9169 - fscore: 0.9169\n",
      "Epoch 99/100\n",
      "650/650 [==============================] - 64s 98ms/step - loss: 0.0051 - acc: 0.9185 - precision: 0.9185 - recall: 0.9185 - fscore: 0.9185\n",
      "Epoch 100/100\n",
      "650/650 [==============================] - 63s 97ms/step - loss: 0.0051 - acc: 0.9215 - precision: 0.9215 - recall: 0.9215 - fscore: 0.9215\n",
      "650/650 [==============================] - 18s 28ms/step\n",
      "[0.00951616730392267, 0.8461538406518789, 0.8464957209733817, 0.8461538406518789, 0.8463157928906955]\n"
     ]
    }
   ],
   "source": [
    "# Declare features for final model\n",
    "use_pos = False\n",
    "use_ner = True\n",
    "use_dpath = True\n",
    "use_tfidf = False\n",
    "use_matching = False\n",
    "\n",
    "# Create batch for final model\n",
    "document_batch, question_batch, answer_batch = generate_batch(full_dataset[:750])\n",
    "\n",
    "# Clear fulldataset since its nolonger needed and saves memory\n",
    "del full_dataset\n",
    "\n",
    "# Create and Train on training data\n",
    "model = create_model(document_batch.shape[2], answer_batch.shape[1], document_batch.shape[1], question_batch.shape[1])\n",
    "train_model(model, document_batch[:650], question_batch[:650], answer_batch[:650], 100)\n",
    "\n",
    "# Evaluate\n",
    "print(model.evaluate([document_batch[650:], question_batch[650:]], [answer_batch[650:]], batch_size=10))\n",
    "\n",
    "# Save model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-9MfVFratY1"
   },
   "source": [
    "#### 2.3.2.2 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_A90cVnaweW"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Declare features for final model\n",
    "use_pos = False\n",
    "use_ner = True\n",
    "use_dpath = True\n",
    "use_tfidf = False\n",
    "use_matching = False\n",
    "\n",
    "# Create Batch\n",
    "document_batch, question_batch, answer_batch = generate_batch(full_dataset[:750])\n",
    "del full_dataset\n",
    "\n",
    "# Load Model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# Evaluate\n",
    "print(model.evaluate([document_batch[650:], question_batch[650:]], [answer_batch[650:]], batch_size=10))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BTEM3257_COMP_ASN2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
